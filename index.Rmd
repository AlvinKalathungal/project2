---
title: 'Project 2: Data Mining, Classification, Prediction'
author: "SDS322E"
date: ''
output:
  html_document:
    toc: yes
    toc_float:
      collapsed: no
      smooth_scroll: yes
  pdf_document:
    toc: no
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = TRUE, fig.align = "center", warning = F, message = F,
tidy=TRUE, tidy.opts=list(width.cutoff=60), R.options=list(max.print=100))

class_diag <- function(score, truth, positive, cutoff=.5){

  pred <- factor(score>cutoff,levels=c("TRUE","FALSE"))
  truth <- factor(truth==positive, levels=c("TRUE","FALSE"))

  tab<-table(truth, pred)
  acc=sum(diag(tab))/sum(tab)
  sens=tab[1,1]/rowSums(tab)[1]
  spec=tab[2,2]/rowSums(tab)[2]
  ppv=tab[1,1]/colSums(tab)[1]

#CALCULATE F1
  f1=2*(sens*ppv)/(sens+ppv)
  
#CALCULATE EXACT AUC
  truth<-as.numeric(truth=="TRUE")
  ord<-order(score, decreasing=TRUE)
  score <- score[ord]; truth <- truth[ord]
  TPR=cumsum(truth)/max(1,sum(truth))
  FPR=cumsum(!truth)/max(1,sum(!truth))
  dup<-c(score[-1]>=score[-length(score)], FALSE)
  TPR<-c(0,TPR[!dup],1); FPR<-c(0,FPR[!dup],1)
  n <- length(TPR)
  auc<- sum( ((TPR[-1]+TPR[-n])/2) * (FPR[-1]-FPR[-n]) )
  round(data.frame(acc,sens,spec,ppv,f1,ba=(sens+spec)/2,auc, row.names = "Metrics"),4)
}
```

# Mining, Classification, Prediction

## Alvin Kalathungal

### Introduction 

So my last project revolved around COVID19, and I collected data about COVID and used R for my Pandemic Science. I was getting tired of looking at COVID19 data, and it is quite depressing. So I chose SMITE Data. SMITE is a third person multiplayer battle arena. Similar to Dota and League of Legends. It qualities are Gods and Monsters of myth as heros in the battlefield. As a nerdy kid who liked video games and mythos, Smite was one of my most played games when I was younger. I recently discovered that they are also adding other properties like RWBY and the Transformers. The main reason why I chose this dataset was due to the transformers advertisement I saw on Youtube and I thought it will be a good idea. Video games ususally have "Metas' (not the mark zuckerberg metaverse), but a catalog of character that are ideal in battle. I was hoping to see correlations in the data and find if there is numbers to prove a meta. 

```{R}
library(tidyverse)
library(dplyr)
library(knitr)
library(ggplot2)
#install.packages("maptools")
library(maptools)
#install.packages("mapdata")
library(mapdata)
#install.packages("ggthemes")
#install.packages("usmap")
library("usmap")
library(ggthemes)
#install.packages("tibble")
library(tibble)
#install.packages("viridis")
library(viridis)
#install.packages("readr")
library(readr)
library(cluster)
```

```{R}
smiteData <- read_csv("SmiteData.csv")
smiteData %>% select(1:4,6,8,10,12,14,16) -> smiteData
names(smiteData)[3] <- 'dmgtype'
names(smiteData)[4] <- 'baseHP'
names(smiteData)[8] <- 'attackPersecond'
names(smiteData)[10] <- 'portPHY'
head(smiteData)

```
 Total attributes that were interesting and renamed columns for ease of use. 
 
### Cluster Analysis

```{R}
library(cluster)

smiteData%>%
    select_if(is.numeric) %>%
    cor(use = "pair") %>%
    as.data.frame %>%
    rownames_to_column("var1") %>%
    pivot_longer(-1, names_to = "var2", values_to = "correlation") ->
    basicStats

basicStats %>%
    ggplot(aes(var1, var2, fill = correlation)) + geom_tile() +
    scale_fill_gradient2(low = "red", mid = "white",
        high = "blue") + geom_text(aes(label = round(correlation,
    2)), color = "black", size = 4) + theme(axis.text.x = element_text(angle = 90,
    hjust = 1)) + coord_fixed()
```

```{r}
sil_width <- vector()
for (i in 2:10) {
    pam_fit <- pam(smiteData, k = i)
    sil_width[i] <- pam_fit$silinfo$avg.width
}
ggplot() + geom_line(aes(x = 1:10, y = sil_width)) +
    scale_x_continuous(name = "k", breaks = 1:10)
```
```{r}
smite_pam <- smiteData%>% pam(k=2)
smite_pam

smiteData %>% slice(smite_pam$id.med)
```
```{r}
plot(smite_pam, which = 2)
```

```{r}
library(GGally)
smiteClust <- smiteData %>%
    mutate(cluster = as.factor(smite_pam$clustering))
ggpairs(smiteClust, columns = 4:10, aes(color = cluster))
```
Did a correlation matrix to see a if there any basic correlations. We see portPHy and BaseHp are correlated at 0.71. Make sense are physical protections and base Hp go hand in hand. We see range is portPHY is negatively correlated. ranged characters would have weaker protections. 
We picked the number of clusters by graphing sil_width with PAM. K=2. We see the gods Ra ( Class: Mage Dmgtype: magical) and Awillix ( Class: Assassin, DMg: type: Physical) We got an average sil_wid of 0.5 whcih is weak associations. When using GGpairs, we see that portpHy is correlated at 0.713. MP and Range are negatively correlated with PortPHy. Speed and Range are negatively correlated. This all makes sense game wise, ranged characters are slower. if they were faster, they would have been overpowered in the game. Overall, the data proven to make sense.  
    
    
### Dimensionality Reduction with PCA

```{R}
princomp(smiteData[4:10], cor = TRUE) -> pca1
summary(pca1, loadings = T)
```
```{r}
eigval <- pca1$sdev^2 #square to convert SDs to eigenvalues
varprop=round(eigval/sum(eigval), 2) #proportion of var explained by each PC

ggplot() + geom_bar(aes(y=varprop, x=1:7), stat="identity") + xlab("") + geom_path(aes(y=varprop, x=1:7)) + 
  geom_text(aes(x=1:7, y=varprop, label=round(varprop, 2)), vjust=1, col="white", size=5) + 
  scale_y_continuous(breaks=seq(0, .6, .2), labels = scales::percent) + scale_x_continuous(breaks=1:10)
```

```{r}
round(cumsum(eigval)/sum(eigval), 2) 
```

```{r}
results <-  smiteData %>% as.data.frame %>% mutate(PC1=pca1$scores[, 1], PC2=pca1$scores[, 2], PC3=pca1$scores[, 3], PC4=pca1$scores[, 4])  #add PCs
  
results %>% ggplot(aes(PC1, PC2, color=Range)) + geom_point(size=4)

results %>% ggplot(aes(PC3, PC4, color=attackPersecond )) + geom_point(size=4)
```
The first ggplot we can see huge correlation with range. The second ggplot which acounts for PCA 3 and PCA 4 accounts for AttackperSecond. 


The Princomp ran with columns 4:10 which wre the numeric variables. and wehen running the PCA,we  see that by PCA 3, we see that 80.5% of the data is understood by then. We can keep up to PCA 3, though I did use up to PCA 4 for the ggplots. We see the that first PCA accounted for 52% when mainly removing MP and Range. The second PCA mainly removed Speed and Attack per second. Rhe there added attack per second and removed Damage. For the first PCa, it make senese, relative good HP would mean you are in frontlines, so your magical use is weaker and involved main damage. The second PCA we see a re low of attack per second, being at -0.634. and high value being 0.434. This confuses me slightly, but I can see heavier characters do slower atttack in the front lines but which would require physical resistance. The third PCA acounts for 80.5% and we see a high of attack per second, with a low damage. These would be the spammy character who shoot a lot but doesn't do a lot of damage. The damage adds over time. 

The First PCA accounts for 52% if the variance, PCA2 accounts for 0.18. PCA3 accounts for 0.1. PCA 4 acounts for 0.07. So the first 4 PCAs accounts for 87% of the total variance. 

###  Linear Classifier

```{R}
smiteData %>% select(3:10) -> classData
classData <- classData %>% mutate(dmgtype = ifelse(dmgtype=="Physical",1,0))

fit <- glm(dmgtype ~ . , data=classData, family="binomial") 
probs <- predict(fit, type="response")
class_diag(probs, classData$dmgtype, positive="1")
table(truth = classData$dmgtype, predictions = probs>.5)
```
```{r}
 smiteData %>% mutate(dmgtype = ifelse(dmgtype=="Physical",1,0)) %>% select(3:10) ->smitedata2
```

```{R}
set.seed(321)
k = 10

data <- sample_frac(smitedata2)  #randomly order rows
folds <- rep(1:k, length.out = nrow(data))  #create folds

diags <- NULL

i = 1
for (i in 1:k) {
    train <- data[folds != i, ]
    test <- data[folds == i, ]
    truth <- test$dmgtype
    
    fit <- glm(dmgtype ~ . , data=train, family="binomial")
    

    probs <- predict(fit, newdata = test, type = "response")
    
    diags <- rbind(diags, class_diag(probs, truth, positive = "1"))
}

# average performance metrics across all folds
summarize_all(diags, mean)
```
For the Smite datasets, Gods are classified as magical or physical. We want to see if the model can id physical charaters/ This is a binary variable. We see that the smite data was gathered and the dmgtype of converted to Os and 1s. The model was trained and we see 46 were true phy characters with the model 38 magical characters. 4 characters were id as magical when physical and 3 were labeled as physical when magical. We see that an AUC score of .9893. This mean 98.93% the model will be accurate. In the cross validation, we see that AUC score decreased to 0.9482, which is a sign of overfitting. 


### Non-Parametric Classifier

```{R}
library(caret)
fit <- knn3(dmgtype ~ . , data=classData)
probs <- predict(fit, newdata=classData)[,2]
class_diag(probs, classData$dmgtype, positive="1") 
table(truth = classData$dmgtype, predictions = probs>.5) %>% addmargins
```

```{R}
set.seed(322)
k = 10

data <- sample_frac(smitedata2) 
folds <- rep(1:k, length.out = nrow(data))  

diags <- NULL

i = 1
for (i in 1:k) {
    # create training and test sets
    train <- data[folds != i, ]
    test <- data[folds == i, ]
    truth <- test$dmgtype
    
    # train model
    fit <- knn3(dmgtype ~ . , data = train)  ### SPECIFY THE KNN MODEL FIT TO THE TRAINING SET HERE
    
    # test model
    probs <- predict(fit, newdata = test)[, 2]
    ### GET PREDICTIONS FROM THE TRAINED MODEL ON THE TEST SET HERE
    
    # get performance metrics for each fold
    diags <- rbind(diags, class_diag(probs, truth, positive = "1"))
}

# average performance metrics across all folds
summarize_all(diags, mean)

```
In the original model, we see an AUC score of 0.9951, which would refer to that 99.51%, the model is able to predict correctly 99.51% of the time. We see that the table shown that the data was able to accurate guess 49 characters are truly as Physical character with 38 truly Magical. four of them has been id falsely labeled as truly magical. In the cross validation we see a decrease of auc to .98. This shows signs of sightly overfitting the data. Compared to the linear classifier, the nonparametric performed better as there was less of a decrease in AUC. 



### Regression/Numeric Prediction

```{R}
fit<- lm(baseHP~., data=smiteData)
yhat<-predict(fit) 
mean((smiteData$baseHP-yhat)^2)
```

```{R}
set.seed(322)
k=2 #choose number of folds
data<-smitedata2[sample(nrow(smitedata2)),] #randomly order rows
folds<-cut(seq(1:nrow(smitedata2)),breaks=k,labels=F) #create folds
diags<-NULL
for(i in 1:k){
train<-data[folds!=i,]
test<-data[folds==i,]
## Fit linear regression model to training set
fit<-lm(baseHP~.,data=train)
## Get predictions/y-hats on test set (fold i)
yhat<-predict(fit,newdata=test)
## Compute prediction error (MSE) for fold i
diags<-mean((test$baseHP-yhat)^2)
}
mean(diags)
```
```{r}
library(rpart); library(rpart.plot)

fit <- train(Speed ~ . , data=smitedata2, method="rpart")
rpart.plot(fit$finalModel,digits=4)

```

I decided to do both a tree and the model. Though my main focus was the model and BaseHP of characters. The model gave use a MSE 7.54*10^-25. So it was pretty accurate. When doing the fold at k=2, we see the mean goes to 1146, which means it is drastically over fittings. This models shows drastic signs of overfitting. The tree was made to understand speed. 

### Python 



```{R}
#R code chunk
library(reticulate)
use_python("/usr/bin/python3")

pythondata<- smiteData$attackPersecond
```

```{python}
## Python code chunk
import numpy as np  
data=(r.pythondata)

#print(data)

dataMedian = (np.median(data))
print(dataMedian)
dataMean = (np.mean(data))
print(dataMean)
dataVar =(np.var(data))
print(dataVar)
dataMin = min(data)
print(dataMin)
dataMax = max(data)
print(dataMax)
```

```{r}
sumATKPerSec = c(py$dataMin,py$dataMean,py$dataMedian, py$dataMax, py$dataVar)
sumATKPerSec
```
Python: I didn't think anyway to be creative for the python section of this project so I decided to replicate what was done in the homework. I was interested in seeing attack per second reflected the smite characters. I grabbed that smite$attackPersecond from python. Moved it to python. Python calculated the values and I grabbed them in R and displayed them in their own variable. 

### Concluding Remarks

Overall, the smite dataset is fascinating. I am quite happy the developers made a lot of sense in their character creation process. 

This was a fun project and I have learned a lot about R throught these two projects. I hope to expand this knowledge in the future and use it in my future careers. Maybe grad school if I so choose to go. I am still deciding on that even though I am graduating in May.  Have a good holiday break Professor Woodward and Mr. Han. Thank you for the knowledge you have bestowed. 




